# Heart-Attack-risk-Prediction
#### Here we will see how to do feature selection using statistical techniques like ANOVA/chisquare test which determines how significant a feature is.
#### We will also look how to use VIF to check for multicollineariy and remove highly correlated features. Removing multicollinearity is very important if we need feature importance. It is also used in high latency applications as removing features reduces time complexity.
#### We will also look at how to treat discrete and continuous variables seperately.
#### At the end we build a linear model(Logistic regression) and a non linear model(XGBOOST) and compare the performances
